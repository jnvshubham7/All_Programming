{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Mini batch gradient with feature scaling and regularised data\n",
      "Final coefficients are : \n",
      "[-0.0009512233653201716, 0.0003455185578924804, 0.0012921439418643614, 0.0012263568786885907, 0.00021592677752947323, 0.00015102949034201903, -0.00013169737969301714, 0.001070106975913077, -0.0006871371154226238, 0.0021405337816332603, 0.0007809511981761315, 0.0012006263335595268, 0.0015324350086064874, 0.0024324525793972237]\n",
      "Accuracy is : 76.92307692307693\n",
      "Now printing the confustion matrix\n",
      "[[26, 4], [17, 44]]\n"
     ]
    }
   ],
   "source": [
    "# Submitted by Shubham Kumar Bhokta (IIT2020007)\n",
    "\n",
    "# In this code I have predicted heart diseases using the clevland medical data. I have used mini batch GDA on regularised and feature scaled data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "def getscaleddata():\n",
    "\tinput_data = pd.read_csv(\"heart_diseases.csv\")\n",
    "\tn = input_data.shape[0]\n",
    "\tY = input_data['y']\n",
    "\tf1 = input_data['f1']\n",
    "\tf1 = (f1 - np.mean(f1)) / (np.max(f1) - np.min(f1))\n",
    "\tf2 = input_data['f2']\n",
    "\tf2 = (f2 - np.mean(f2)) / (np.max(f2) - np.min(f2))\n",
    "\tf3 = input_data['f3']\n",
    "\tf3 = (f3 - np.mean(f3)) / (np.max(f3) - np.min(f3))\n",
    "\tf4 = input_data['f4']\n",
    "\tf4 = (f4 - np.mean(f4)) / (np.max(f4) - np.min(f4))\n",
    "\tf5 = input_data['f5']\n",
    "\tf5 = (f5 - np.mean(f5)) / (np.max(f5) - np.min(f5))\n",
    "\tf6 = input_data['f6']\n",
    "\tf6 = (f6 - np.mean(f6)) / (np.max(f6) - np.min(f6))\n",
    "\tf7 = input_data['f7']\n",
    "\tf7 = (f7 - np.mean(f7)) / (np.max(f7) - np.min(f7))\n",
    "\tf8 = input_data['f8']\n",
    "\tf8 = (f8 - np.mean(f8)) / (np.max(f8) - np.min(f8))\n",
    "\tf9 = input_data['f9']\n",
    "\tf9 = (f9 - np.mean(f9)) / (np.max(f9) - np.min(f9))\n",
    "\tf10 = input_data['f10']\n",
    "\tf10 = (f10 - np.mean(f10)) / (np.max(f10) - np.min(f10))\n",
    "\tf11 = input_data['f11']\n",
    "\tf11 = (f11 - np.mean(f11)) / (np.max(f11) - np.min(f11))\n",
    "\tf12 = input_data['f12']\n",
    "\tf12 = (f12 - np.mean(f12)) / (np.max(f12) - np.min(f12))\n",
    "\tf13 = input_data['f13']\n",
    "\tf13 = (f13 - np.mean(f13)) / (np.max(f13) - np.min(f13))\n",
    "\tX_train = []\n",
    "\tX_test = []\n",
    "\tY_train = []\n",
    "\tY_test = []\n",
    "\tfor i in range(int(0.7 * n)):\n",
    "\t\tX_train.append([1, f1[i], f2[i], f3[i], f4[i], f5[i], f6[i], f7[i], f8[i], f9[i], f10[i], f11[i], f12[i], f13[i]])\n",
    "\t\tY_train.append(Y[i])\n",
    "\n",
    "\tfor i in range(int(0.7 * n), n):\n",
    "\t\tX_test.append([1, f1[i], f2[i], f3[i], f4[i], f5[i], f6[i], f7[i], f8[i], f9[i], f10[i], f11[i], f12[i], f13[i]])\n",
    "\t\tY_test.append(Y[i])\n",
    "\treturn X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + math.exp(-1 * z))\n",
    "\n",
    "def minibtchgrareg(X_train, Y_train, alpha = 0.000000001, epochs = 30, batchsize = 20, LambdaParameter = 10):\n",
    "\tLearningRateScaling = alpha\n",
    "\tCoeff = [0] * len(X_train[0])\n",
    "\tNoOfBatches = math.ceil(len(Y_train) / batchsize)\n",
    "\tequallyDiv = False\n",
    "\tif (len(Y_train) % batchsize == 0):\n",
    "\t\tequallyDiv = True;\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tfor batch in range(NoOfBatches):\n",
    "\t\t\tSummation = [0] * len(X_train[0])\n",
    "\t\t\tfor j in range(len(Coeff)):\n",
    "\t\t\t\tfor i in range(batchsize):\n",
    "\t\t\t\t\tif (batch * batchsize + i == len(X_train)):\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\tPredictedValue = 0.0\n",
    "\t\t\t\t\tfor wj in range(len(Coeff)):\n",
    "\t\t\t\t\t\tPredictedValue += Coeff[wj] * X_train[batch * batchsize + i][wj]\n",
    "\t\t\t\t\tPredictedValue = sigmoid(PredictedValue)\n",
    "\t\t\t\t\tPredictedValue -= Y_train[batch * batchsize + i]\n",
    "\t\t\t\t\tPredictedValue *= X_train[batch * batchsize + i][j]\n",
    "\t\t\t\t\tSummation[j] += PredictedValue;\n",
    "\n",
    "\t\t\tif (not equallyDiv and batch == NoOfBatches - 1):\n",
    "\t\t\t\tfor j in range(len(Summation)):\n",
    "\t\t\t\t\tif j == 0:\n",
    "\t\t\t\t\t\tCoeff[j] = Coeff[j] - (Summation[j] / (len(Y_train) % batchsize)) * LearningRateScaling\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tCoeff[j] = (1 - LearningRateScaling * LambdaParameter / (len(Y_test) % batchsize)) * Coeff[j] - (Summation[j] / (len(Y_train) % batchsize)) * LearningRateScaling\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor j in range(len(Summation)):\n",
    "\t\t\t\t\tif j == 0:\n",
    "\t\t\t\t\t\tCoeff[j] = Coeff[j] - (Summation[j] / batchsize) * LearningRateScaling\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tCoeff[j] = (1 - LearningRateScaling * LambdaParameter / batchsize) * Coeff[j] - (Summation[j] / batchsize) * LearningRateScaling\n",
    "\treturn Coeff\n",
    "\n",
    "# Finding Accuracy\n",
    "def printaccuracy(X_test, Y_test, Coeff):\n",
    "\tcount = 0\n",
    "\tfor i in range(len(X_test)):\n",
    "\t\tpredicted = 0\n",
    "\t\tfor j in range(len(Coeff)):\n",
    "\t\t  \tpredicted = predicted + Coeff[j] * X_test[i][j]\n",
    "\t\tpredicted = sigmoid(predicted)\n",
    "\t\tif predicted > 0.5:\n",
    "\t\t\tif Y_test[i] == 1:\n",
    "\t\t\t\tcount += 1\n",
    "\t\telse:\n",
    "\t\t\tif Y_test[i] == 0:\n",
    "\t\t\t\tcount += 1\n",
    "\tprint(\"Accuracy is : \" + str(count / len(Y_test) * 100))\n",
    "\n",
    "def getconfusionmat(X_test, Y_test, Coeff):\n",
    "\ttruepositives = 0\n",
    "\tfalsepositives = 0\n",
    "\ttruenegatives = 0\n",
    "\tfalsenegatives = 0\n",
    "\tfor i in range(len(X_test)):\n",
    "\t\tpredicted = 0\n",
    "\t\tfor j in range(len(Coeff)):\n",
    "\t\t  \tpredicted = predicted + Coeff[j] * X_test[i][j]\n",
    "\t\tpredicted = sigmoid(predicted)\n",
    "\t\tif predicted > 0.5:\n",
    "\t\t\tif Y_test[i] == 1:\n",
    "\t\t\t\ttruepositives += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tfalsepositives += 1\n",
    "\t\telse:\n",
    "\t\t\tif Y_test[i] == 0:\n",
    "\t\t\t\ttruenegatives += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tfalsenegatives += 1\n",
    "\tpredictedpositive = []\n",
    "\tpredictednegative = []\n",
    "\tconfustionmatrix = []\n",
    "\tpredictedpositive.append(truepositives)\n",
    "\tpredictedpositive.append(falsepositives)\n",
    "\tpredictednegative.append(falsenegatives)\n",
    "\tpredictednegative.append(truenegatives)\n",
    "\tconfustionmatrix.append(predictedpositive)\n",
    "\tconfustionmatrix.append(predictednegative)\n",
    "\treturn confustionmatrix\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = getscaleddata()\n",
    "print(\"Doing Mini batch gradient with feature scaling and regularised data\")\n",
    "coeff = minibtchgrareg(X_train, Y_train, 0.00001, 500, 64, 10)\n",
    "print(\"Final coefficients are : \")\n",
    "print(coeff)\n",
    "printaccuracy(X_test, Y_test, coeff)\n",
    "print(\"Now printing the confustion matrix\")\n",
    "print(getconfusionmat(X_test, Y_test, coeff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
